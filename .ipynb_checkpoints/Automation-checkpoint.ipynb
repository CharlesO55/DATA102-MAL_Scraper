{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b68480e-d135-45d9-a981-cb4ee2505f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d97f3-8ffd-46d0-9375-ea5eb1b44b3c",
   "metadata": {},
   "source": [
    "# READ\n",
    "> Don't try to actually run all cells. It would take too long from the delay added <br>\n",
    "> Just choose which segments require testing.\n",
    ">\n",
    "> Reduce `MINIMUM_DELAY` at your own risk of being blocked\n",
    "\n",
    "> To perform scraping of `Details`, `StatisticsSummary`, `StatisticsSubmissions`, ensure there's a `csv` already in `Season/`.<br>\n",
    "> Otherwise run `AutomateSeason()` in the `Seasons` segment to generate the database of anime links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d11f80-d6e5-4ca4-9da7-324a45411ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scraper.MINIMUM_DELAY = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89004b25-a659-485a-aea1-88a02da182f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c5962f-5d7d-4334-be74-639bcc5c570d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4bc09-876f-463a-9211-a70088178e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutomateSeason(YEARS : List[str]):\n",
    "    for YEAR in YEARS:\n",
    "        for SEASON in Scraper.SEASONS.__members__.values():\n",
    "            url = Scraper.build_URL_Seasons(YEAR, SEASON)\n",
    "            print(url)\n",
    "    \n",
    "            try:\n",
    "                seasonalSoup = Scraper.scrape(url)\n",
    "                df_Season = pd.DataFrame(SeasonPage.parse(seasonalSoup))\n",
    "    \n",
    "                filename = f'Season/{YEAR}_{SEASON.value}.csv'\n",
    "                df_Season.to_csv(filename)\n",
    "                print(filename)\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(url, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae1389-d3fa-401a-b325-bd9c1bbec508",
   "metadata": {},
   "source": [
    "## 1. Scrape All 1996 Seasons Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c63b4-b854-4dfd-a098-6abe6a6bf4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutomateSeason(np.arange(1995, 1996))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e455568-2e82-4003-a7c5-b5ec53c42936",
   "metadata": {},
   "source": [
    "## 2. Scrape Modern Anime (2020-2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fea4b1-9725-42ed-912e-a7fe14280545",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutomateSeason(np.arange(2020, 2026))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d29e59-0028-4194-a769-618ddce454fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c14ed-516f-49b8-873f-618725a6b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a636a-39ed-458e-b19d-d45d698eb2a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Scrape [First 2, 2 Random, and Last 2] Anime from 1995 Fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedcec3b-ba92-41eb-973a-319b15c82d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASON = Scraper.SEASONS.FALL.value\n",
    "YEAR = 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47281945-662b-49f8-93ed-6f59c5c0edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'Season/{YEAR}_{SEASON}.csv', index_col=0)\n",
    "df_Target = df.iloc[[0,1,\n",
    "                np.random.randint(2,df.shape[0]-2),\n",
    "                np.random.randint(2,df.shape[0]-2),\n",
    "                -2,-1]].copy()\n",
    "\n",
    "df_Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dcae5e-947a-49f7-ab37-11360a8f328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Details = None\n",
    "\n",
    "for _, row in df_Target.iterrows():\n",
    "    output = {}\n",
    "    newRow = None\n",
    "    \n",
    "    try:\n",
    "        soup = Scraper.scrape(row.Link)\n",
    "        output = DetailsPage.parse(soup)\n",
    "        output['Title'] = row.Title\n",
    "\n",
    "        newRow = pd.DataFrame([output])\n",
    "        \n",
    "        if df_Details is None:\n",
    "            df_Details = newRow\n",
    "        else:\n",
    "            df_Details = pd.concat([df_Details, newRow], ignore_index=True)\n",
    "        \n",
    "        print(row.Title)\n",
    "    except Exception as e:\n",
    "        print(f'ERROR: {row.Link} {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962d127-3f0b-4ac6-b53b-efdc0a1f1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'Detail/{YEAR}_{SEASON}_sample.csv'\n",
    "df_Details.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0664b-9312-4196-9387-8db403a43777",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Scrape All Entries From Specific Year and Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084f8ae-9726-4cb8-932d-ea2ff4556920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutomateDetails(YEAR : int | str, SEASON : Scraper.SEASONS):\n",
    "    df_Details = None\n",
    "\n",
    "    for _, row in pd.read_csv(f'Season/{YEAR}_{SEASON.value}.csv').iterrows():\n",
    "        output = {}\n",
    "        newRow = None\n",
    "        \n",
    "        try:\n",
    "            soup = Scraper.scrape(row.Link)\n",
    "            output = DetailsPage.parse(soup)\n",
    "            output['Title'] = row.Title\n",
    "    \n",
    "            newRow = pd.DataFrame([output])\n",
    "            \n",
    "            if df_Details is None:\n",
    "                df_Details = newRow\n",
    "            else:\n",
    "                df_Details = pd.concat([df_Details, newRow], ignore_index=True)\n",
    "            \n",
    "            print(row.Title)\n",
    "        except Exception as e:\n",
    "            print(f'ERROR: {row.Link} {e}')    \n",
    "        \n",
    "    filename = f'Detail/{YEAR}_{SEASON.value}.csv'\n",
    "    df_Details.to_csv(filename)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b615488-4b04-4b84-8dcf-691fd817fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutomateDetails(2024, Scraper.SEASONS.FALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345782c6-3048-495e-a3fa-2a88e66318f9",
   "metadata": {},
   "source": [
    "# Statistics [1] Summary and [2] Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234009b-2532-4c4c-b2d3-feea2f036c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d31c7-c80a-4cf7-a154-7be3190a7f93",
   "metadata": {},
   "source": [
    "## 1. Get the Scores of Every Anime in Season and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017f6b9-ab65-4e94-b8c4-89bf49ba8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutomateStatSummary(YEAR:int, SEASONS:Scraper.SEASONS) -> pd.DataFrame:\n",
    "    df_StatSummary = None\n",
    "    \n",
    "    for _, row in pd.read_csv(f'Season/{YEAR}_{SEASON.value}.csv', index_col=0).iterrows():\n",
    "        URL = f'{row.Link}/stats'\n",
    "        print(URL)\n",
    "    \n",
    "        try:\n",
    "            soup = Scraper.scrape(URL)\n",
    "            data = StatisticsSummaryPage.parse(soup)\n",
    "            data['Title'] = row.Title\n",
    "        \n",
    "            if df_StatSummary is None: \n",
    "                df_StatSummary = pd.DataFrame([data])\n",
    "            else:\n",
    "                df_StatSummary = pd.concat([df_StatSummary, pd.DataFrame([data])], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f'ERROR URL {e}')\n",
    "        \n",
    "    filename = f'Statistics/Summary/{YEAR}_{SEASON.value}.csv'\n",
    "    print(filename)\n",
    "    df_StatSummary.to_csv(filename)\n",
    "    \n",
    "    return df_StatSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66ebcd-63ff-4a4b-9a7c-645e69058ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YEAR = 2024\n",
    "#SEASON = Scraper.SEASONS.FALL\n",
    "\n",
    "for YEAR in np.arange(2020, 2025):\n",
    "    for SEASON in Scraper.SEASONS.__members__.values():\n",
    "        AutomateStatSummary(YEAR, SEASON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eef643-6fa3-4794-a940-acf54181e4a8",
   "metadata": {},
   "source": [
    "## 2. Scrape the Latest Viewership across <= 100 Pages for a Given Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e866ae-af37-4d92-bb4b-fff3663e07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutomateStatSubmissions(TITLE : str, LINK : str):\n",
    "    df_Statistics = None\n",
    "    \n",
    "    for i in np.arange(0, 75*100, 75):\n",
    "        try:\n",
    "            URL = f'{LINK}/stats?show={i}#members'\n",
    "            print(URL)\n",
    "    \n",
    "            soup = Scraper.scrape(URL)\n",
    "    \n",
    "            \n",
    "            if df_Statistics is None:\n",
    "                df_Statistics = StatisticsSubmissionPage.parseAsDf(soup)\n",
    "            else:\n",
    "                df_Statistics = pd.concat([df_Statistics, StatisticsSubmissionPage.parseAsDf(soup)], ignore_index=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'END {e}')\n",
    "            break\n",
    "    \n",
    "    filename = f'Statistics/Submissions/{TITLE}.csv'\n",
    "    df_Statistics.to_csv(filename)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d8c20-cb2e-4b5b-b7eb-84793b058051",
   "metadata": {},
   "source": [
    "### Try EVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d2455-b763-4171-81e6-488ed918dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVA = pd.read_csv('Season/1995_fall.csv', index_col=0).loc[0]\n",
    "\n",
    "AutomateStatSubmissions(TITLE=EVA.Title, LINK=EVA.Link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
